{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6043bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarShot Project Starter Notebook\n",
    "# ---------------------------------\n",
    "# Sections: Data Loading, Preprocessing, Embedding, Vector DB Creation\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a213444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "DATASET_NAME = \"SALT-NLP/silent_signals\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "VECTOR_DB_PATH = \"./vector_store\"\n",
    "CLASSIFIER_MODEL = \"cardiffnlp/twitter-roberta-base-hate\"\n",
    "# unitary/toxic-bert didnt seem to work that well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e07fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Silent Signals dataset...\n",
      "Loaded 16258 labeled entries.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Load Dataset\n",
    "# -------------------------------\n",
    "print(\"Loading Silent Signals dataset...\")\n",
    "dataset = load_dataset(DATASET_NAME, split='train')\n",
    "df = pd.DataFrame(dataset)\n",
    "# Clean Dataset\n",
    "# drop the party, chamber, and speaker columns\n",
    "df = df.drop(columns=['party', 'chamber', 'speaker'])\n",
    "# Filter if necessary (e.g., only Reddit posts, or only dog-whistle-labeled)\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(df)} labeled entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c0c4bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f83260ea23a42f38cd022dfcc1204ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Sentence Embeddings\n",
    "# -------------------------------\n",
    "print(\"Generating embeddings...\")\n",
    "model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "texts = df['content'].tolist()  # Adjust column name if needed\n",
    "embeddings = model.encode(texts, batch_size=32, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a646d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ChromaDB vector store...\n",
      "Collection deletion failed or doesn't exist yet: Collection [earshot] does not exists\n",
      "Stored 16258 vectors in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating ChromaDB vector store...\")\n",
    "chroma_client = chromadb.Client(Settings(persist_directory=VECTOR_DB_PATH))\n",
    "# reset the collection if it exists\n",
    "try:\n",
    "    chroma_client.delete_collection(\"earshot\")\n",
    "except Exception as e:\n",
    "    print(\"Collection deletion failed or doesn't exist yet:\", e)\n",
    "collection = chroma_client.create_collection(\"earshot\")\n",
    "\n",
    "# Add embeddings to vector DB (skip numpy by converting to list via torch.tolist())\n",
    "for i, (text, emb) in enumerate(zip(texts, embeddings)):\n",
    "    collection.add(\n",
    "        documents=[text],\n",
    "        embeddings=[emb.cpu().tolist()],\n",
    "        ids=[f\"doc_{i}\"]\n",
    "    )\n",
    "\n",
    "print(f\"Stored {len(texts)} vectors in ChromaDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d57b62d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors for: Far left SJW/Woke activists use a variety of words with double meanings intentionally, including privilege, inclusion, comfort, and safety. Equity is no different. In the past, equity meant fairness or debt paid off, but under Theory, it brings neo-marxist intent.\n",
      " - Far left SJW/Woke activists use a variety of words with double meanings intentionally, including privilege, inclusion, comfort, and safety. Equity is no different. In the past, equity meant fairness or debt paid off, but under Theory, it brings neo-marxist intent.\n",
      " - It is time for a revolution but not the lefts version of equity, CRT, socialism, etc, one where people learn the games of the rich to make yourself a weapon of equality.\n",
      " - There were always two alt rights. There was Spencer and the Alt-Right of ethnonationalism and there was the catch-all alternative right who were conservatives with ideas that put them outside of the mainstream. Spencer coined the term in 2008.\n",
      " - Privilege as used by SJWs is just something to guilt people with so SJWs can gain the moral high ground.\n",
      " - Alt-right is two (horible and ignorant) things. Race realism and white genocide. Those are the common ideology shared by almost everyone who identifies with them.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Nearest Neighbor Retrieval\n",
    "# -------------------------------\n",
    "def get_neighbors(query_text, k=5):\n",
    "    query_emb = model.encode([query_text], convert_to_tensor=True)[0].cpu().tolist()\n",
    "    results = collection.query(query_embeddings=[query_emb], n_results=k)\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "example_query = texts[0]\n",
    "neighbors = get_neighbors(example_query)\n",
    "print(\"Nearest Neighbors for:\", example_query)\n",
    "for doc in neighbors['documents'][0]:\n",
    "    print(\" -\", doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a005019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading custom toxicity classifier model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cccafe9b30143229d5520150a633153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7aac6483d224d04a5830670341faf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbda702353145d9874868ddcafa1346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4760a1cd84ea462eaaaad17b2fc0f7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c79aed4aa746beb7ae69c2e38ce791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PREDICT on nearest neighbors...\n",
      "Retrieved 5 neighbor posts.\n",
      "Neighbor 1 | Toxicity Score: 0.085\n",
      "Neighbor 1 | Toxic: False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc14cd3dea274b12b263e84f538a314f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor 2 | Toxicity Score: 0.084\n",
      "Neighbor 2 | Toxic: False\n",
      "Neighbor 3 | Toxicity Score: 0.038\n",
      "Neighbor 3 | Toxic: False\n",
      "Neighbor 4 | Toxicity Score: 0.056\n",
      "Neighbor 4 | Toxic: False\n",
      "Neighbor 5 | Toxicity Score: 0.085\n",
      "Neighbor 5 | Toxic: False\n",
      "PREDICT returned 0 toxic posts with keywords.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# PREDICT Pipeline: Filter + Keyword Extraction\n",
    "# -------------------------------\n",
    "\n",
    "# Load classifier manually to bypass numpy issue\n",
    "print(\"Loading custom toxicity classifier model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(CLASSIFIER_MODEL)\n",
    "classifier_model = AutoModelForSequenceClassification.from_pretrained(CLASSIFIER_MODEL)\n",
    "classifier_model.eval()\n",
    "\n",
    "# Initialize YAKE keyword extractor\n",
    "kw_extractor = yake.KeywordExtractor(top=5, stopwords=None)\n",
    "\n",
    "def is_toxic(text, threshold=0.5):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier_model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)[0]\n",
    "    toxic_score = probs[1].item()  # assuming label 1 = toxic\n",
    "    return toxic_score >= threshold\n",
    "\n",
    "def extract_keywords(text):\n",
    "    return [kw for kw, score in kw_extractor.extract_keywords(text)]\n",
    "# Run PREDICT on neighbors of example query\n",
    "print(\"Running PREDICT on nearest neighbors...\")\n",
    "example_query = texts[0]\n",
    "neighbors = get_neighbors(example_query, k=5)\n",
    "predict_results = []\n",
    "\n",
    "print(f\"Retrieved {len(neighbors['documents'][0])} neighbor posts.\")\n",
    "\n",
    "def get_toxic_score(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier_model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)[0]\n",
    "    return probs[1].item()\n",
    "\n",
    "for i, post in enumerate(neighbors['documents'][0]):\n",
    "    score_raw = get_toxic_score(post)\n",
    "    print(f\"Neighbor {i+1} | Toxicity Score: {score_raw:.3f}\")\n",
    "    if score_raw >= 0.3:\n",
    "        print(f\"Neighbor {i+1} | Toxic: True\")\n",
    "        keywords = extract_keywords(post)\n",
    "        predict_results.append({\n",
    "            'post': post,\n",
    "            'keywords': keywords\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Neighbor {i+1} | Toxic: False\")\n",
    "\n",
    "print(f\"PREDICT returned {len(predict_results)} toxic posts with keywords.\")\n",
    "for result in predict_results:\n",
    "    print(\"Post:\", result['post'])\n",
    "    print(\"Extracted Keywords:\", result['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# DIRECT Pipeline: LLM Prompting for Dog Whistle Detection\n",
    "# -------------------------------\n",
    "\n",
    "# Set OpenAI API Key from environment\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def call_llm_direct(post):\n",
    "    prompt = f\"\"\"\n",
    "You are a content moderation assistant. Identify whether the following post contains any covert hate speech or dog whistles.\n",
    "\n",
    "Return your response in the following JSON format:\n",
    "{{\n",
    "  \"is_dog_whistle\": true/false,\n",
    "  \"dog_whistle_terms\": [\"term1\", \"term2\", ...],\n",
    "  \"explanation\": \"brief explanation of detection or why it's not a dog whistle\"\n",
    "}}\n",
    "\n",
    "Post: \"{post}\"\n",
    "\"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# Run DIRECT on neighbors of example query\n",
    "print(\"\\nRunning DIRECT on nearest neighbors...\")\n",
    "direct_results = []\n",
    "\n",
    "for post in neighbors['documents'][0]:\n",
    "    try:\n",
    "        analysis = call_llm_direct(post)\n",
    "        direct_results.append({\n",
    "            'post': post,\n",
    "            'llm_response': analysis\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(\"Error calling LLM:\", e)\n",
    "\n",
    "# Show results\n",
    "for result in direct_results:\n",
    "    print(\"\\nPost:\", result['post'])\n",
    "    print(\"LLM Response:\", result['llm_response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
